volumes:
  sqlite_data:
    driver: local
    driver_opts:
      type: none
      device: ${SQLITE_DATA_DIR}
      o: bind
  ollama_models: {}  # Named volume to persist models

services:
  bot:
    build: .
    container_name: telegram-bot
    env_file: .env
    volumes:
      - sqlite_data:/app/tg_data.db
    ports:
      - "8080:8080"
    expose:
      - 8080
    restart: unless-stopped
    depends_on:
      - ollama

  tuna:
    image: yuccastream/tuna
    command: http 8080 --inspect=false --subdomain=${SUB_DOMAIN}
    env_file: .env
    restart: always
    network_mode: "host"

  ollama-init:
    image: alpine:latest
    env_file: .env
    depends_on:
      - ollama
    volumes:
      - ollama_models:/root/.ollama
    command: >
      sh -c "
      apk add --no-cache curl bash &&
      chmod +x ollama &&
      echo 'Waiting for Ollama API to be ready...' &&
      until curl -f http://${OLLAMA_HOST}:${OLLAMA_PORT}/api/version; do
        sleep 2;
      done;
      echo 'Ollama is ready. Pulling ${OLLAMA_MODEL_NAME} model...' &&
      ./ollama pull ${OLLAMA_MODEL_NAME} &&
      echo 'Model ${OLLAMA_MODEL_NAME} pulled successfully.'"

  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    env_file: .env
    ports:
      - "${OLLAMA_PORT}:${OLLAMA_PORT}"
    volumes:
      - ollama_models:/root/.ollama
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://${OLLAMA_HOST}:${OLLAMA_PORT}/api/version" ]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped